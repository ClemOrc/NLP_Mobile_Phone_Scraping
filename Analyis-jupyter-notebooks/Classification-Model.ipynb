{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9dc1791-3cbc-4f97-ba26-8ce704805763",
   "metadata": {},
   "source": [
    "# Building Classifier and Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e554ead-c43a-43cd-b9f0-1abb70c0994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Collecting typing_extensions==4.7.1\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: typing_extensions\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "Successfully installed typing_extensions-4.7.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.6.0 requires typing-extensions>=4.10.0, but you have typing-extensions 4.7.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\python\\anaconda\\lib\\site-packages (2.6.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.6.0-cp311-cp311-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in d:\\python\\anaconda\\lib\\site-packages (from torch) (3.13.1)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: networkx in d:\\python\\anaconda\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\python\\anaconda\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in d:\\python\\anaconda\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\python\\anaconda\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\python\\anaconda\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\python\\anaconda\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\python\\anaconda\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\python\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torchvision-0.21.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.6 MB 640.0 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.1/1.6 MB 1.8 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.4/1.6 MB 3.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.4/1.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.8/1.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.6 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.6 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.6/1.6 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.6.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.5 MB 2.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.2/2.5 MB 1.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.4/2.5 MB 1.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.6/2.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.5 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.0/2.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.2/2.5 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.3/2.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.5/2.5 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.5 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.0/2.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.3/2.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 3.7 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, torchvision, torchaudio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "Successfully installed torchaudio-2.6.0 torchvision-0.21.0 typing-extensions-4.12.2\n",
      "Requirement already satisfied: transformers in d:\\python\\anaconda\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in d:\\python\\anaconda\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in d:\\python\\anaconda\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\python\\anaconda\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\python\\anaconda\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\python\\anaconda\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\python\\anaconda\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in d:\\python\\anaconda\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\python\\anaconda\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\python\\anaconda\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\python\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\python\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\python\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in d:\\python\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\anaconda\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall typing_extensions torch torchvision torchaudio\n",
    "!pip install typing_extensions==4.7.1\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ec33e-948a-4ed1-9921-a54f6004cafa",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c783d7-b12b-43b7-a635-e2ea83ee5cf2",
   "metadata": {},
   "source": [
    "## Classification based on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4800158f-31c0-40c5-a284-6e3f35b696f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Processing Google Pixel...\n",
      "Accuracy: 0.65\n",
      "Positive ratio: 24.78%\n",
      "Negative ratio: 75.22%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.86      0.73       518\n",
      "           1       0.68      0.38      0.49       402\n",
      "\n",
      "    accuracy                           0.65       920\n",
      "   macro avg       0.66      0.62      0.61       920\n",
      "weighted avg       0.66      0.65      0.63       920\n",
      "\n",
      "\n",
      "Processing Oppo Find X3 Pro...\n",
      "Accuracy: 0.68\n",
      "Positive ratio: 23.60%\n",
      "Negative ratio: 76.40%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77       210\n",
      "           1       0.64      0.40      0.49       129\n",
      "\n",
      "    accuracy                           0.68       339\n",
      "   macro avg       0.67      0.63      0.63       339\n",
      "weighted avg       0.68      0.68      0.66       339\n",
      "\n",
      "\n",
      "Processing Samsung S24 Ultra...\n",
      "Accuracy: 0.79\n",
      "Positive ratio: 13.92%\n",
      "Negative ratio: 86.08%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       287\n",
      "           1       0.67      0.36      0.46       101\n",
      "\n",
      "    accuracy                           0.79       388\n",
      "   macro avg       0.74      0.65      0.67       388\n",
      "weighted avg       0.77      0.79      0.76       388\n",
      "\n",
      "\n",
      "Processing Xiaomi 14 Ultra...\n",
      "Accuracy: 0.64\n",
      "Positive ratio: 15.46%\n",
      "Negative ratio: 84.54%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.92      0.75      1012\n",
      "           1       0.71      0.26      0.38       747\n",
      "\n",
      "    accuracy                           0.64      1759\n",
      "   macro avg       0.67      0.59      0.56      1759\n",
      "weighted avg       0.66      0.64      0.59      1759\n",
      "\n",
      "\n",
      "Processing iPhone...\n",
      "Accuracy: 0.72\n",
      "Positive ratio: 18.03%\n",
      "Negative ratio: 81.97%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.93      0.80       589\n",
      "           1       0.77      0.36      0.50       365\n",
      "\n",
      "    accuracy                           0.72       954\n",
      "   macro avg       0.74      0.65      0.65       954\n",
      "weighted avg       0.73      0.72      0.68       954\n",
      "\n",
      "\n",
      "Overall Brand Sentiment Comparison:\n",
      "--------------------------------------------------\n",
      "\n",
      "Brand Sentiment Summary:\n",
      "            Brand Accuracy Positive Ratio Negative Ratio\n",
      "     Google Pixel     0.65         24.78%         75.22%\n",
      " Oppo Find X3 Pro     0.68         23.60%         76.40%\n",
      "Samsung S24 Ultra     0.79         13.92%         86.08%\n",
      "  Xiaomi 14 Ultra     0.64         15.46%         84.54%\n",
      "           iPhone     0.72         18.03%         81.97%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "\n",
    "class BrandSentimentClassifier:\n",
    "    def __init__(self, k=5):\n",
    "        \"\"\"Initialize the classifier\"\"\"\n",
    "        self.k = k\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            stop_words='english',\n",
    "            min_df=2,\n",
    "            max_df=0.95,\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "\n",
    "    def prepare_data(self, df, brand):\n",
    "        \"\"\"Prepare data for specific brand\"\"\"\n",
    "        # Filter reviews for specific brand\n",
    "        brand_df = df[df['Product Brand'] == brand].copy()\n",
    "        \n",
    "        if len(brand_df) < 10:  # Too little data\n",
    "            return None, None\n",
    "            \n",
    "        # Set initial labels (based on keywords)\n",
    "        positive_keywords = {\n",
    "       \n",
    "            'good', 'great', 'nice', 'fine', 'decent', 'positive',\n",
    "            \n",
    "          \n",
    "            'excellent', 'amazing', 'fantastic', 'awesome', 'perfect', 'superb',\n",
    "            'outstanding', 'exceptional', 'remarkable', 'brilliant', 'wonderful',\n",
    "            'impressive', 'incredible', 'marvelous', 'magnificent',\n",
    "            \n",
    "         \n",
    "            'love', 'like', 'enjoy', 'admire', 'appreciate', 'satisfied',\n",
    "            'happy', 'pleased', 'delighted', 'fond', \n",
    "            \n",
    "            \n",
    "            'best', 'superior', 'premium', 'top-notch', 'first-rate', 'high-end',\n",
    "            'leading', 'outstanding', 'elite', 'prime', 'stellar',\n",
    "            \n",
    "           \n",
    "            'fast', 'smooth', 'stable', 'reliable', 'efficient', 'powerful',\n",
    "            'responsive', 'quick', 'seamless', 'robust',\n",
    "            \n",
    "          \n",
    "            'recommend', 'worth', 'recommended', 'valuable', 'worthwhile',\n",
    "            \n",
    "          \n",
    "            'exceeded', 'surpassed', 'beyond', 'surprised', 'impressive',\n",
    "            'extraordinary', 'exceptional', 'astounding',\n",
    "            \n",
    "        \n",
    "            'quality', 'premium', 'refined', 'polished', 'solid', 'durable',\n",
    "            'well-built', 'well-made',\n",
    "            \n",
    "          \n",
    "            'innovative', 'advanced', 'cutting-edge', 'revolutionary', 'state-of-the-art',\n",
    "            'breakthrough', 'pioneering',\n",
    "            \n",
    "      \n",
    "            'comfortable', 'convenient', 'handy', 'user-friendly', 'intuitive',\n",
    "            'practical', 'versatile', 'flexible'\n",
    "        }\n",
    "        brand_df['Label'] = brand_df['Text'].str.lower().apply(\n",
    "            lambda x: 1 if any(word in str(x) for word in positive_keywords) else 0\n",
    "        )\n",
    "        \n",
    "        return brand_df['Text'], brand_df['Label']\n",
    "\n",
    "    def classify_review(self, test_vec, train_vecs, train_labels):\n",
    "        \"\"\"KNN classification based on similarity\"\"\"\n",
    "        # Calculate similarity\n",
    "        similarities = cosine_similarity(test_vec, train_vecs).flatten()\n",
    "        \n",
    "        # Get indices of k most similar documents\n",
    "        top_k_indices = np.argsort(similarities)[-self.k:][::-1]\n",
    "        \n",
    "        # Get labels for these k documents\n",
    "        top_k_labels = [train_labels[i] for i in top_k_indices]\n",
    "        \n",
    "        # Return majority label\n",
    "        return Counter(top_k_labels).most_common(1)[0][0]\n",
    "\n",
    "    def train_and_evaluate(self, df, brand):\n",
    "        \"\"\"Train and evaluate the model\"\"\"\n",
    "        print(f\"\\nProcessing {brand}...\")\n",
    "        \n",
    "        # Prepare data\n",
    "        X, y = self.prepare_data(df, brand)\n",
    "        if X is None:\n",
    "            print(f\"Insufficient data for {brand}\")\n",
    "            return None\n",
    "            \n",
    "        # Split training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Convert to TF-IDF features\n",
    "        X_train_tfidf = self.vectorizer.fit_transform(X_train)\n",
    "        X_test_tfidf = self.vectorizer.transform(X_test)\n",
    "        \n",
    "        # Reset indices\n",
    "        y_train = y_train.reset_index(drop=True)\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "        \n",
    "        # Predict test set\n",
    "        y_pred = []\n",
    "        for i in range(X_test_tfidf.shape[0]):\n",
    "            test_vector = X_test_tfidf[i:i+1]\n",
    "            pred_label = self.classify_review(test_vector, X_train_tfidf, y_train)\n",
    "            y_pred.append(pred_label)\n",
    "            \n",
    "        # Evaluate results\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        pos_ratio = sum(y_pred) / len(y_pred)\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"Positive ratio: {pos_ratio:.2%}\")\n",
    "        print(f\"Negative ratio: {(1-pos_ratio):.2%}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'report': report,\n",
    "            'positive_ratio': pos_ratio,\n",
    "            'negative_ratio': 1 - pos_ratio,\n",
    "            'predictions': y_pred,\n",
    "            'true_labels': y_test\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv('all_brands_combined_mobile_data_final.csv')\n",
    "    \n",
    "    # Create classifier\n",
    "    classifier = BrandSentimentClassifier(k=5)\n",
    "    \n",
    "    # Brands to analyze\n",
    "    brands = ['Google Pixel', 'Oppo Find X3 Pro', 'Samsung S24 Ultra', \n",
    "              'Xiaomi 14 Ultra', 'iPhone']\n",
    "    \n",
    "    # Analyze each brand\n",
    "    results = {}\n",
    "    for brand in brands:\n",
    "        result = classifier.train_and_evaluate(df, brand)\n",
    "        if result:\n",
    "            results[brand] = result\n",
    "    \n",
    "    # Print overall comparison results\n",
    "    print(\"\\nOverall Brand Sentiment Comparison:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_data = []\n",
    "    for brand in brands:\n",
    "        if brand in results:\n",
    "            comparison_data.append({\n",
    "                'Brand': brand,\n",
    "                'Accuracy': f\"{results[brand]['accuracy']:.2f}\",\n",
    "                'Positive Ratio': f\"{results[brand]['positive_ratio']:.2%}\",\n",
    "                'Negative Ratio': f\"{results[brand]['negative_ratio']:.2%}\"\n",
    "            })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(\"\\nBrand Sentiment Summary:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a597abf-2bbd-43fa-bc78-93129052ea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Processing Google Pixel...\n",
      "Accuracy: 0.72\n",
      "Positive ratio: 14.13%\n",
      "Negative ratio: 85.87%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82       621\n",
      "           1       0.65      0.28      0.39       299\n",
      "\n",
      "    accuracy                           0.72       920\n",
      "   macro avg       0.69      0.60      0.60       920\n",
      "weighted avg       0.70      0.72      0.68       920\n",
      "\n",
      "\n",
      "Processing Oppo Find X3 Pro...\n",
      "Accuracy: 0.71\n",
      "Positive ratio: 17.70%\n",
      "Negative ratio: 82.30%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.89      0.81       233\n",
      "           1       0.57      0.32      0.41       106\n",
      "\n",
      "    accuracy                           0.71       339\n",
      "   macro avg       0.65      0.60      0.61       339\n",
      "weighted avg       0.69      0.71      0.68       339\n",
      "\n",
      "\n",
      "Processing Samsung S24 Ultra...\n",
      "Accuracy: 0.82\n",
      "Positive ratio: 8.76%\n",
      "Negative ratio: 91.24%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       310\n",
      "           1       0.62      0.27      0.38        78\n",
      "\n",
      "    accuracy                           0.82       388\n",
      "   macro avg       0.73      0.61      0.63       388\n",
      "weighted avg       0.79      0.82      0.79       388\n",
      "\n",
      "\n",
      "Processing Xiaomi 14 Ultra...\n",
      "Accuracy: 0.72\n",
      "Positive ratio: 10.23%\n",
      "Negative ratio: 89.77%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82      1195\n",
      "           1       0.72      0.23      0.35       564\n",
      "\n",
      "    accuracy                           0.72      1759\n",
      "   macro avg       0.72      0.59      0.59      1759\n",
      "weighted avg       0.72      0.72      0.67      1759\n",
      "\n",
      "\n",
      "Processing iPhone...\n",
      "Accuracy: 0.76\n",
      "Positive ratio: 12.79%\n",
      "Negative ratio: 87.21%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85       682\n",
      "           1       0.66      0.30      0.41       272\n",
      "\n",
      "    accuracy                           0.76       954\n",
      "   macro avg       0.72      0.62      0.63       954\n",
      "weighted avg       0.74      0.76      0.72       954\n",
      "\n",
      "\n",
      "Overall Brand Sentiment Comparison:\n",
      "--------------------------------------------------\n",
      "\n",
      "Brand Sentiment Summary:\n",
      "            Brand Accuracy Positive Ratio Negative Ratio\n",
      "     Google Pixel     0.72         14.13%         85.87%\n",
      " Oppo Find X3 Pro     0.71         17.70%         82.30%\n",
      "Samsung S24 Ultra     0.82          8.76%         91.24%\n",
      "  Xiaomi 14 Ultra     0.72         10.23%         89.77%\n",
      "           iPhone     0.76         12.79%         87.21%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "\n",
    "class BrandSentimentClassifier:\n",
    "    def __init__(self, k=5):\n",
    "        \"\"\"Initialize the classifier\"\"\"\n",
    "        self.k = k\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            stop_words='english',\n",
    "            min_df=2,\n",
    "            max_df=0.95,\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "\n",
    "    def prepare_data(self, df, brand):\n",
    "        \"\"\"Prepare data for specific brand\"\"\"\n",
    "        # Filter reviews for specific brand\n",
    "        brand_df = df[df['Product Brand'] == brand].copy()\n",
    "        \n",
    "        if len(brand_df) < 10:  # Too little data\n",
    "            return None, None\n",
    "            \n",
    "     \n",
    "        positive_keywords = {\n",
    "          \n",
    "            'good', 'great', 'nice', 'fine', 'decent', 'positive',\n",
    "          \n",
    "            'excellent', 'amazing', 'fantastic', 'awesome', 'perfect', 'superb',\n",
    "            'outstanding', 'exceptional', 'remarkable', 'brilliant', 'wonderful',\n",
    "            'impressive', 'incredible', 'marvelous', 'magnificent',\n",
    "            \n",
    "        \n",
    "            'love', 'like', 'enjoy', 'admire', 'appreciate', 'satisfied',\n",
    "            'happy', 'pleased', 'delighted', 'fond',\n",
    "            \n",
    "         \n",
    "            'best', 'superior', 'premium', 'top-notch', 'first-rate', 'high-end',\n",
    "            'leading', 'outstanding', 'elite', 'prime', 'stellar',\n",
    "            \n",
    "          \n",
    "            'fast', 'smooth', 'stable', 'reliable', 'efficient', 'powerful',\n",
    "            'responsive', 'quick', 'seamless', 'robust',\n",
    "            \n",
    "     \n",
    "            'recommend', 'worth', 'recommended', 'valuable', 'worthwhile',\n",
    "            \n",
    "         \n",
    "            'exceeded', 'surpassed', 'beyond', 'surprised', 'impressive',\n",
    "            'extraordinary', 'exceptional', 'astounding',\n",
    "            \n",
    "         \n",
    "            'quality', 'premium', 'refined', 'polished', 'solid', 'durable',\n",
    "            'well-built', 'well-made',\n",
    "            \n",
    "         \n",
    "            'innovative', 'advanced', 'cutting-edge', 'revolutionary', 'state-of-the-art',\n",
    "            'breakthrough', 'pioneering',\n",
    "            \n",
    "         \n",
    "            'comfortable', 'convenient', 'handy', 'user-friendly', 'intuitive',\n",
    "            'practical', 'versatile', 'flexible'\n",
    "        }\n",
    "\n",
    "       \n",
    "        negative_keywords = {\n",
    "          \n",
    "            'bad', 'poor', 'terrible', 'horrible', 'awful', 'negative',\n",
    "            \n",
    "      \n",
    "            'defective', 'broken', 'faulty', 'damaged', 'malfunctioning',\n",
    "            'defect', 'flawed', 'inferior', 'cheap', 'low-quality',\n",
    "            \n",
    "  \n",
    "            'slow', 'sluggish', 'laggy', 'unstable', 'unreliable', 'weak',\n",
    "            'unresponsive', 'crash', 'freeze', 'hang', 'bug', 'glitch',\n",
    "            \n",
    "          \n",
    "            'hate', 'dislike', 'disappointed', 'disappointing', 'dissatisfied',\n",
    "            'unhappy', 'frustrated', 'annoyed', 'annoying', 'irritating',\n",
    "            \n",
    "        \n",
    "            'expensive', 'overpriced', 'costly', 'pricey', 'overvalued',\n",
    "            'not worth', 'waste', 'wasted',\n",
    "            \n",
    "        \n",
    "            'difficult', 'complicated', 'confusing', 'awkward', 'clunky',\n",
    "            'cumbersome', 'unintuitive', 'impractical',\n",
    "            \n",
    "           \n",
    "            'rude', 'unhelpful', 'unresponsive', 'poor service', 'bad support',\n",
    "            \n",
    "           \n",
    "            'avoid', 'return', 'returned', 'refund', 'regret',\n",
    "            'mistake', 'error', 'problem', 'issue', 'concern',\n",
    "            \n",
    "       \n",
    "            'worst', 'disaster', 'catastrophe', 'nightmare', 'horrible',\n",
    "            'terrible', 'useless', 'worthless', 'garbage', 'junk',\n",
    "            \n",
    "           \n",
    "            'warranty', 'repair', 'replace', 'replacement', 'defect',\n",
    "            'malfunction', 'break', 'broke'\n",
    "        }\n",
    "        \n",
    "        \n",
    "        def determine_sentiment(text):\n",
    "            text = str(text).lower()\n",
    "            has_positive = any(word in text for word in positive_keywords)\n",
    "            has_negative = any(word in text for word in negative_keywords)\n",
    "            \n",
    "            if has_positive and not has_negative:\n",
    "                return 1 \n",
    "            elif has_negative and not has_positive:\n",
    "                return 0  \n",
    "            elif has_positive and has_negative:\n",
    "              \n",
    "                positive_count = sum(1 for word in positive_keywords if word in text)\n",
    "                negative_count = sum(1 for word in negative_keywords if word in text)\n",
    "                return 1 if positive_count > negative_count else 0\n",
    "            else:\n",
    "                return 0\n",
    "        \n",
    "        brand_df['Label'] = brand_df['Text'].apply(determine_sentiment)\n",
    "        \n",
    "        return brand_df['Text'], brand_df['Label']\n",
    "\n",
    "    def classify_review(self, test_vec, train_vecs, train_labels):\n",
    "        \"\"\"KNN classification based on similarity\"\"\"\n",
    "        # Calculate similarity\n",
    "        similarities = cosine_similarity(test_vec, train_vecs).flatten()\n",
    "        \n",
    "        # Get indices of k most similar documents\n",
    "        top_k_indices = np.argsort(similarities)[-self.k:][::-1]\n",
    "        \n",
    "        # Get labels for these k documents\n",
    "        top_k_labels = [train_labels[i] for i in top_k_indices]\n",
    "        \n",
    "        # Return majority label\n",
    "        return Counter(top_k_labels).most_common(1)[0][0]\n",
    "\n",
    "    def train_and_evaluate(self, df, brand):\n",
    "        \"\"\"Train and evaluate the model\"\"\"\n",
    "        print(f\"\\nProcessing {brand}...\")\n",
    "        \n",
    "        # Prepare data\n",
    "        X, y = self.prepare_data(df, brand)\n",
    "        if X is None:\n",
    "            print(f\"Insufficient data for {brand}\")\n",
    "            return None\n",
    "            \n",
    "        # Split training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Convert to TF-IDF features\n",
    "        X_train_tfidf = self.vectorizer.fit_transform(X_train)\n",
    "        X_test_tfidf = self.vectorizer.transform(X_test)\n",
    "        \n",
    "        # Reset indices\n",
    "        y_train = y_train.reset_index(drop=True)\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "        \n",
    "        # Predict test set\n",
    "        y_pred = []\n",
    "        for i in range(X_test_tfidf.shape[0]):\n",
    "            test_vector = X_test_tfidf[i:i+1]\n",
    "            pred_label = self.classify_review(test_vector, X_train_tfidf, y_train)\n",
    "            y_pred.append(pred_label)\n",
    "            \n",
    "        # Evaluate results\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        pos_ratio = sum(y_pred) / len(y_pred)\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(f\"Positive ratio: {pos_ratio:.2%}\")\n",
    "        print(f\"Negative ratio: {(1-pos_ratio):.2%}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'report': report,\n",
    "            'positive_ratio': pos_ratio,\n",
    "            'negative_ratio': 1 - pos_ratio,\n",
    "            'predictions': y_pred,\n",
    "            'true_labels': y_test\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv('all_brands_combined_mobile_data_final.csv')\n",
    "    \n",
    "    # Create classifier\n",
    "    classifier = BrandSentimentClassifier(k=5)\n",
    "    \n",
    "    # Brands to analyze\n",
    "    brands = ['Google Pixel', 'Oppo Find X3 Pro', 'Samsung S24 Ultra', \n",
    "              'Xiaomi 14 Ultra', 'iPhone']\n",
    "    \n",
    "    # Analyze each brand\n",
    "    results = {}\n",
    "    for brand in brands:\n",
    "        result = classifier.train_and_evaluate(df, brand)\n",
    "        if result:\n",
    "            results[brand] = result\n",
    "    \n",
    "    # Print overall comparison results\n",
    "    print(\"\\nOverall Brand Sentiment Comparison:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_data = []\n",
    "    for brand in brands:\n",
    "        if brand in results:\n",
    "            comparison_data.append({\n",
    "                'Brand': brand,\n",
    "                'Accuracy': f\"{results[brand]['accuracy']:.2f}\",\n",
    "                'Positive Ratio': f\"{results[brand]['positive_ratio']:.2%}\",\n",
    "                'Negative Ratio': f\"{results[brand]['negative_ratio']:.2%}\"\n",
    "            })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(\"\\nBrand Sentiment Summary:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4c1c350-16a7-4e70-98af-7f355fa372d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Processing Google Pixel...\n",
      "Training classifier for battery life\n",
      "Accuracy: 0.74\n",
      "Positive ratio: 43.69%\n",
      "Negative ratio: 56.31%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78        63\n",
      "           1       0.64      0.72      0.68        40\n",
      "\n",
      "    accuracy                           0.74       103\n",
      "   macro avg       0.73      0.74      0.73       103\n",
      "weighted avg       0.75      0.74      0.74       103\n",
      "\n",
      "Training classifier for camera\n",
      "Accuracy: 0.76\n",
      "Positive ratio: 40.97%\n",
      "Negative ratio: 59.03%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80        86\n",
      "           1       0.69      0.71      0.70        58\n",
      "\n",
      "    accuracy                           0.76       144\n",
      "   macro avg       0.75      0.75      0.75       144\n",
      "weighted avg       0.76      0.76      0.76       144\n",
      "\n",
      "Training classifier for design\n",
      "Accuracy: 0.75\n",
      "Positive ratio: 36.47%\n",
      "Negative ratio: 63.53%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81        55\n",
      "           1       0.65      0.67      0.66        30\n",
      "\n",
      "    accuracy                           0.75        85\n",
      "   macro avg       0.73      0.73      0.73        85\n",
      "weighted avg       0.75      0.75      0.75        85\n",
      "\n",
      "Training classifier for display\n",
      "Accuracy: 0.73\n",
      "Positive ratio: 32.97%\n",
      "Negative ratio: 67.03%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80        62\n",
      "           1       0.57      0.59      0.58        29\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.68      0.69      0.69        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n",
      "Training classifier for performance\n",
      "Accuracy: 0.68\n",
      "Positive ratio: 48.98%\n",
      "Negative ratio: 51.02%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.66      0.72        61\n",
      "           1       0.56      0.73      0.64        37\n",
      "\n",
      "    accuracy                           0.68        98\n",
      "   macro avg       0.68      0.69      0.68        98\n",
      "weighted avg       0.71      0.68      0.69        98\n",
      "\n",
      "Training classifier for software\n",
      "Accuracy: 0.78\n",
      "Positive ratio: 16.89%\n",
      "Negative ratio: 83.11%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       234\n",
      "           1       0.46      0.37      0.41        62\n",
      "\n",
      "    accuracy                           0.78       296\n",
      "   macro avg       0.65      0.63      0.64       296\n",
      "weighted avg       0.76      0.78      0.77       296\n",
      "\n",
      "Training classifier for speaker\n",
      "Accuracy: 0.65\n",
      "Positive ratio: 27.03%\n",
      "Negative ratio: 72.97%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78        32\n",
      "           1       0.10      0.20      0.13         5\n",
      "\n",
      "    accuracy                           0.65        37\n",
      "   macro avg       0.48      0.46      0.46        37\n",
      "weighted avg       0.75      0.65      0.69        37\n",
      "\n",
      "\n",
      "Processing Oppo Find X3 Pro...\n",
      "Training classifier for battery life\n",
      "Accuracy: 0.81\n",
      "Positive ratio: 19.23%\n",
      "Negative ratio: 80.77%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        40\n",
      "           1       0.60      0.50      0.55        12\n",
      "\n",
      "    accuracy                           0.81        52\n",
      "   macro avg       0.73      0.70      0.71        52\n",
      "weighted avg       0.80      0.81      0.80        52\n",
      "\n",
      "Training classifier for camera\n",
      "Accuracy: 0.65\n",
      "Positive ratio: 29.58%\n",
      "Negative ratio: 70.42%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.80      0.73        41\n",
      "           1       0.62      0.43      0.51        30\n",
      "\n",
      "    accuracy                           0.65        71\n",
      "   macro avg       0.64      0.62      0.62        71\n",
      "weighted avg       0.64      0.65      0.63        71\n",
      "\n",
      "Training classifier for design\n",
      "Accuracy: 0.73\n",
      "Positive ratio: 21.21%\n",
      "Negative ratio: 78.79%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82        23\n",
      "           1       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.73        33\n",
      "   macro avg       0.67      0.63      0.64        33\n",
      "weighted avg       0.71      0.73      0.71        33\n",
      "\n",
      "Training classifier for display\n",
      "Accuracy: 0.77\n",
      "Positive ratio: 28.21%\n",
      "Negative ratio: 71.79%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85        31\n",
      "           1       0.45      0.62      0.53         8\n",
      "\n",
      "    accuracy                           0.77        39\n",
      "   macro avg       0.67      0.72      0.69        39\n",
      "weighted avg       0.80      0.77      0.78        39\n",
      "\n",
      "Training classifier for performance\n",
      "Accuracy: 0.82\n",
      "Positive ratio: 33.33%\n",
      "Negative ratio: 66.67%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        20\n",
      "           1       0.82      0.69      0.75        13\n",
      "\n",
      "    accuracy                           0.82        33\n",
      "   macro avg       0.82      0.80      0.80        33\n",
      "weighted avg       0.82      0.82      0.81        33\n",
      "\n",
      "Training classifier for software\n",
      "Accuracy: 0.70\n",
      "Positive ratio: 17.02%\n",
      "Negative ratio: 82.98%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80        64\n",
      "           1       0.56      0.30      0.39        30\n",
      "\n",
      "    accuracy                           0.70        94\n",
      "   macro avg       0.65      0.60      0.60        94\n",
      "weighted avg       0.68      0.70      0.67        94\n",
      "\n",
      "Training classifier for speaker\n",
      "Accuracy: 0.75\n",
      "Positive ratio: 41.67%\n",
      "Negative ratio: 58.33%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77         6\n",
      "           1       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.76      0.75      0.75        12\n",
      "weighted avg       0.76      0.75      0.75        12\n",
      "\n",
      "\n",
      "Processing Samsung S24 Ultra...\n",
      "Training classifier for battery life\n",
      "Accuracy: 0.91\n",
      "Positive ratio: 5.36%\n",
      "Negative ratio: 94.64%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        48\n",
      "           1       1.00      0.38      0.55         8\n",
      "\n",
      "    accuracy                           0.91        56\n",
      "   macro avg       0.95      0.69      0.75        56\n",
      "weighted avg       0.92      0.91      0.89        56\n",
      "\n",
      "Training classifier for camera\n",
      "Accuracy: 0.79\n",
      "Positive ratio: 17.24%\n",
      "Negative ratio: 82.76%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        24\n",
      "           1       0.40      0.40      0.40         5\n",
      "\n",
      "    accuracy                           0.79        29\n",
      "   macro avg       0.64      0.64      0.64        29\n",
      "weighted avg       0.79      0.79      0.79        29\n",
      "\n",
      "Training classifier for design\n",
      "Accuracy: 0.74\n",
      "Positive ratio: 8.70%\n",
      "Negative ratio: 91.30%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85        19\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.74        23\n",
      "   macro avg       0.40      0.45      0.43        23\n",
      "weighted avg       0.67      0.74      0.70        23\n",
      "\n",
      "Training classifier for display\n",
      "Accuracy: 0.95\n",
      "Positive ratio: 1.56%\n",
      "Negative ratio: 98.44%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        60\n",
      "           1       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.95        64\n",
      "   macro avg       0.98      0.62      0.69        64\n",
      "weighted avg       0.96      0.95      0.94        64\n",
      "\n",
      "Training classifier for performance\n",
      "Accuracy: 0.88\n",
      "Positive ratio: 23.53%\n",
      "Negative ratio: 76.47%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        13\n",
      "           1       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.84      0.84      0.84        17\n",
      "weighted avg       0.88      0.88      0.88        17\n",
      "\n",
      "Training classifier for software\n",
      "Accuracy: 0.86\n",
      "Positive ratio: 6.17%\n",
      "Negative ratio: 93.83%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        67\n",
      "           1       0.80      0.29      0.42        14\n",
      "\n",
      "    accuracy                           0.86        81\n",
      "   macro avg       0.83      0.64      0.67        81\n",
      "weighted avg       0.86      0.86      0.84        81\n",
      "\n",
      "Training classifier for speaker\n",
      "Accuracy: 0.50\n",
      "Positive ratio: 50.00%\n",
      "Negative ratio: 50.00%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         4\n",
      "           1       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.50      0.50      0.50         8\n",
      "weighted avg       0.50      0.50      0.50         8\n",
      "\n",
      "\n",
      "Processing Xiaomi 14 Ultra...\n",
      "Training classifier for battery life\n",
      "Accuracy: 0.67\n",
      "Positive ratio: 35.43%\n",
      "Negative ratio: 64.57%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       140\n",
      "           1       0.56      0.53      0.54        83\n",
      "\n",
      "    accuracy                           0.67       223\n",
      "   macro avg       0.64      0.64      0.64       223\n",
      "weighted avg       0.67      0.67      0.67       223\n",
      "\n",
      "Training classifier for camera\n",
      "Accuracy: 0.73\n",
      "Positive ratio: 36.78%\n",
      "Negative ratio: 63.22%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79       234\n",
      "           1       0.62      0.63      0.63       133\n",
      "\n",
      "    accuracy                           0.73       367\n",
      "   macro avg       0.71      0.71      0.71       367\n",
      "weighted avg       0.73      0.73      0.73       367\n",
      "\n",
      "Training classifier for design\n",
      "Accuracy: 0.67\n",
      "Positive ratio: 46.39%\n",
      "Negative ratio: 53.61%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.69        90\n",
      "           1       0.64      0.64      0.64        76\n",
      "\n",
      "    accuracy                           0.67       166\n",
      "   macro avg       0.67      0.67      0.67       166\n",
      "weighted avg       0.67      0.67      0.67       166\n",
      "\n",
      "Training classifier for display\n",
      "Accuracy: 0.58\n",
      "Positive ratio: 54.41%\n",
      "Negative ratio: 45.59%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.53      0.61        83\n",
      "           1       0.47      0.66      0.55        53\n",
      "\n",
      "    accuracy                           0.58       136\n",
      "   macro avg       0.59      0.60      0.58       136\n",
      "weighted avg       0.62      0.58      0.59       136\n",
      "\n",
      "Training classifier for performance\n",
      "Accuracy: 0.71\n",
      "Positive ratio: 35.08%\n",
      "Negative ratio: 64.92%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76       112\n",
      "           1       0.67      0.57      0.62        79\n",
      "\n",
      "    accuracy                           0.71       191\n",
      "   macro avg       0.70      0.69      0.69       191\n",
      "weighted avg       0.70      0.71      0.70       191\n",
      "\n",
      "Training classifier for software\n",
      "Accuracy: 0.71\n",
      "Positive ratio: 17.46%\n",
      "Negative ratio: 82.54%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.89      0.81       362\n",
      "           1       0.57      0.32      0.40       165\n",
      "\n",
      "    accuracy                           0.71       527\n",
      "   macro avg       0.65      0.60      0.61       527\n",
      "weighted avg       0.69      0.71      0.68       527\n",
      "\n",
      "Training classifier for speaker\n",
      "Accuracy: 0.63\n",
      "Positive ratio: 46.51%\n",
      "Negative ratio: 53.49%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.62      0.69        29\n",
      "           1       0.45      0.64      0.53        14\n",
      "\n",
      "    accuracy                           0.63        43\n",
      "   macro avg       0.62      0.63      0.61        43\n",
      "weighted avg       0.67      0.63      0.64        43\n",
      "\n",
      "\n",
      "Processing iPhone...\n",
      "Training classifier for battery life\n",
      "Accuracy: 0.80\n",
      "Positive ratio: 12.77%\n",
      "Negative ratio: 87.23%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       188\n",
      "           1       0.50      0.32      0.39        47\n",
      "\n",
      "    accuracy                           0.80       235\n",
      "   macro avg       0.67      0.62      0.64       235\n",
      "weighted avg       0.78      0.80      0.78       235\n",
      "\n",
      "Training classifier for camera\n",
      "Accuracy: 0.81\n",
      "Positive ratio: 12.37%\n",
      "Negative ratio: 87.63%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.88       149\n",
      "           1       0.52      0.32      0.40        37\n",
      "\n",
      "    accuracy                           0.81       186\n",
      "   macro avg       0.68      0.63      0.64       186\n",
      "weighted avg       0.78      0.81      0.79       186\n",
      "\n",
      "Training classifier for design\n",
      "Accuracy: 0.76\n",
      "Positive ratio: 29.33%\n",
      "Negative ratio: 70.67%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        53\n",
      "           1       0.59      0.59      0.59        22\n",
      "\n",
      "    accuracy                           0.76        75\n",
      "   macro avg       0.71      0.71      0.71        75\n",
      "weighted avg       0.76      0.76      0.76        75\n",
      "\n",
      "Training classifier for display\n",
      "Accuracy: 0.78\n",
      "Positive ratio: 12.00%\n",
      "Negative ratio: 88.00%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87        93\n",
      "           1       0.67      0.31      0.43        32\n",
      "\n",
      "    accuracy                           0.78       125\n",
      "   macro avg       0.73      0.63      0.65       125\n",
      "weighted avg       0.77      0.78      0.75       125\n",
      "\n",
      "Training classifier for performance\n",
      "Accuracy: 0.73\n",
      "Positive ratio: 14.55%\n",
      "Negative ratio: 85.45%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83        40\n",
      "           1       0.50      0.27      0.35        15\n",
      "\n",
      "    accuracy                           0.73        55\n",
      "   macro avg       0.63      0.58      0.59        55\n",
      "weighted avg       0.69      0.73      0.70        55\n",
      "\n",
      "Training classifier for software\n",
      "Accuracy: 0.81\n",
      "Positive ratio: 12.39%\n",
      "Negative ratio: 87.61%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       194\n",
      "           1       0.41      0.30      0.35        40\n",
      "\n",
      "    accuracy                           0.81       234\n",
      "   macro avg       0.64      0.61      0.62       234\n",
      "weighted avg       0.79      0.81      0.80       234\n",
      "\n",
      "Training classifier for speaker\n",
      "Accuracy: 0.65\n",
      "Positive ratio: 17.65%\n",
      "Negative ratio: 82.35%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75        10\n",
      "           1       0.67      0.29      0.40         7\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.65      0.59      0.57        17\n",
      "weighted avg       0.65      0.65      0.61        17\n",
      "\n",
      "\n",
      "Overall Sentiment Analysis Results:\n",
      "\n",
      "Google Pixel Analysis:\n",
      "--------------------------------------------------\n",
      "\n",
      "Battery Life:\n",
      "Accuracy: 0.74\n",
      "Positive ratio: 43.69%\n",
      "Negative ratio: 56.31%\n",
      "\n",
      "Camera:\n",
      "Accuracy: 0.76\n",
      "Positive ratio: 40.97%\n",
      "Negative ratio: 59.03%\n",
      "\n",
      "Design:\n",
      "Accuracy: 0.75\n",
      "Positive ratio: 36.47%\n",
      "Negative ratio: 63.53%\n",
      "\n",
      "Display:\n",
      "Accuracy: 0.73\n",
      "Positive ratio: 32.97%\n",
      "Negative ratio: 67.03%\n",
      "\n",
      "Performance:\n",
      "Accuracy: 0.68\n",
      "Positive ratio: 48.98%\n",
      "Negative ratio: 51.02%\n",
      "\n",
      "Software:\n",
      "Accuracy: 0.78\n",
      "Positive ratio: 16.89%\n",
      "Negative ratio: 83.11%\n",
      "\n",
      "Speaker:\n",
      "Accuracy: 0.65\n",
      "Positive ratio: 27.03%\n",
      "Negative ratio: 72.97%\n",
      "\n",
      "Oppo Find X3 Pro Analysis:\n",
      "--------------------------------------------------\n",
      "\n",
      "Battery Life:\n",
      "Accuracy: 0.81\n",
      "Positive ratio: 19.23%\n",
      "Negative ratio: 80.77%\n",
      "\n",
      "Camera:\n",
      "Accuracy: 0.65\n",
      "Positive ratio: 29.58%\n",
      "Negative ratio: 70.42%\n",
      "\n",
      "Design:\n",
      "Accuracy: 0.73\n",
      "Positive ratio: 21.21%\n",
      "Negative ratio: 78.79%\n",
      "\n",
      "Display:\n",
      "Accuracy: 0.77\n",
      "Positive ratio: 28.21%\n",
      "Negative ratio: 71.79%\n",
      "\n",
      "Performance:\n",
      "Accuracy: 0.82\n",
      "Positive ratio: 33.33%\n",
      "Negative ratio: 66.67%\n",
      "\n",
      "Software:\n",
      "Accuracy: 0.70\n",
      "Positive ratio: 17.02%\n",
      "Negative ratio: 82.98%\n",
      "\n",
      "Speaker:\n",
      "Accuracy: 0.75\n",
      "Positive ratio: 41.67%\n",
      "Negative ratio: 58.33%\n",
      "\n",
      "Samsung S24 Ultra Analysis:\n",
      "--------------------------------------------------\n",
      "\n",
      "Battery Life:\n",
      "Accuracy: 0.91\n",
      "Positive ratio: 5.36%\n",
      "Negative ratio: 94.64%\n",
      "\n",
      "Camera:\n",
      "Accuracy: 0.79\n",
      "Positive ratio: 17.24%\n",
      "Negative ratio: 82.76%\n",
      "\n",
      "Design:\n",
      "Accuracy: 0.74\n",
      "Positive ratio: 8.70%\n",
      "Negative ratio: 91.30%\n",
      "\n",
      "Display:\n",
      "Accuracy: 0.95\n",
      "Positive ratio: 1.56%\n",
      "Negative ratio: 98.44%\n",
      "\n",
      "Performance:\n",
      "Accuracy: 0.88\n",
      "Positive ratio: 23.53%\n",
      "Negative ratio: 76.47%\n",
      "\n",
      "Software:\n",
      "Accuracy: 0.86\n",
      "Positive ratio: 6.17%\n",
      "Negative ratio: 93.83%\n",
      "\n",
      "Speaker:\n",
      "Accuracy: 0.50\n",
      "Positive ratio: 50.00%\n",
      "Negative ratio: 50.00%\n",
      "\n",
      "Xiaomi 14 Ultra Analysis:\n",
      "--------------------------------------------------\n",
      "\n",
      "Battery Life:\n",
      "Accuracy: 0.67\n",
      "Positive ratio: 35.43%\n",
      "Negative ratio: 64.57%\n",
      "\n",
      "Camera:\n",
      "Accuracy: 0.73\n",
      "Positive ratio: 36.78%\n",
      "Negative ratio: 63.22%\n",
      "\n",
      "Design:\n",
      "Accuracy: 0.67\n",
      "Positive ratio: 46.39%\n",
      "Negative ratio: 53.61%\n",
      "\n",
      "Display:\n",
      "Accuracy: 0.58\n",
      "Positive ratio: 54.41%\n",
      "Negative ratio: 45.59%\n",
      "\n",
      "Performance:\n",
      "Accuracy: 0.71\n",
      "Positive ratio: 35.08%\n",
      "Negative ratio: 64.92%\n",
      "\n",
      "Software:\n",
      "Accuracy: 0.71\n",
      "Positive ratio: 17.46%\n",
      "Negative ratio: 82.54%\n",
      "\n",
      "Speaker:\n",
      "Accuracy: 0.63\n",
      "Positive ratio: 46.51%\n",
      "Negative ratio: 53.49%\n",
      "\n",
      "iPhone Analysis:\n",
      "--------------------------------------------------\n",
      "\n",
      "Battery Life:\n",
      "Accuracy: 0.80\n",
      "Positive ratio: 12.77%\n",
      "Negative ratio: 87.23%\n",
      "\n",
      "Camera:\n",
      "Accuracy: 0.81\n",
      "Positive ratio: 12.37%\n",
      "Negative ratio: 87.63%\n",
      "\n",
      "Design:\n",
      "Accuracy: 0.76\n",
      "Positive ratio: 29.33%\n",
      "Negative ratio: 70.67%\n",
      "\n",
      "Display:\n",
      "Accuracy: 0.78\n",
      "Positive ratio: 12.00%\n",
      "Negative ratio: 88.00%\n",
      "\n",
      "Performance:\n",
      "Accuracy: 0.73\n",
      "Positive ratio: 14.55%\n",
      "Negative ratio: 85.45%\n",
      "\n",
      "Software:\n",
      "Accuracy: 0.81\n",
      "Positive ratio: 12.39%\n",
      "Negative ratio: 87.61%\n",
      "\n",
      "Speaker:\n",
      "Accuracy: 0.65\n",
      "Positive ratio: 17.65%\n",
      "Negative ratio: 82.35%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "\n",
    "class MobileReviewClassifier:\n",
    "    def __init__(self, k=5):\n",
    "        \"\"\"\n",
    "        Initialize the classifier\n",
    "        k: number of neighbors in KNN algorithm\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            stop_words='english',\n",
    "            min_df=2,  # minimum document frequency\n",
    "            max_df=0.95,  # maximum document frequency\n",
    "            ngram_range=(1, 2)  # use unigrams and bigrams\n",
    "        )\n",
    "        \n",
    "        self.dimension_keywords = {\n",
    "            'battery life': ['battery', 'battery life', 'charge', 'charging', 'power'],\n",
    "            'camera': ['camera', 'photo', 'picture', 'image', 'photography', 'shoot'],\n",
    "            'design': ['design', 'build', 'look', 'build quality', 'material'],\n",
    "            'display': ['display', 'screen', 'resolution', 'brightness', 'color'],\n",
    "            'performance': ['performance', 'speed', 'fast', 'slow', 'processor', 'lag'],\n",
    "            'software': ['software', 'system', 'os', 'android', 'ios', 'interface'],\n",
    "            'speaker': ['speaker', 'sound', 'audio', 'volume', 'music']\n",
    "        }\n",
    "\n",
    "    def prepare_data(self, df, brand, dimension):\n",
    "        \"\"\"Prepare data for specific brand and dimension\"\"\"\n",
    "        # Filter reviews for specific brand\n",
    "        brand_df = df[df['Product Brand'] == brand].copy()\n",
    "        \n",
    "        # Filter reviews containing relevant keywords\n",
    "        keywords = self.dimension_keywords[dimension]\n",
    "        mask = brand_df['Text'].str.lower().apply(lambda x: any(keyword in x for keyword in keywords))\n",
    "        dimension_df = brand_df[mask].copy()\n",
    "        \n",
    "        if len(dimension_df) < 10:  # Too little data\n",
    "            return None, None\n",
    "            \n",
    "        # Set initial labels for training (needs to be adjusted based on actual situation)\n",
    "        # Assumes reviews containing positive keywords are positive\n",
    "        positive_keywords = {'good', 'great', 'excellent', 'amazing', 'love', 'perfect'}\n",
    "        dimension_df['Label'] = dimension_df['Text'].str.lower().apply(\n",
    "            lambda x: 1 if any(word in x for word in positive_keywords) else 0\n",
    "        )\n",
    "        \n",
    "        return dimension_df['Text'], dimension_df['Label']\n",
    "\n",
    "    def classify_review(self, test_vec, train_vecs, train_labels):\n",
    "        \"\"\"KNN classification based on similarity\"\"\"\n",
    "        # Calculate similarity\n",
    "        similarities = cosine_similarity(test_vec, train_vecs).flatten()\n",
    "        \n",
    "        # Get indices of k most similar documents\n",
    "        top_k_indices = np.argsort(similarities)[-self.k:][::-1]\n",
    "        \n",
    "        # Get labels for these k documents\n",
    "        top_k_labels = [train_labels[i] for i in top_k_indices]\n",
    "        \n",
    "        # Return majority label\n",
    "        return Counter(top_k_labels).most_common(1)[0][0]\n",
    "\n",
    "    def train_and_evaluate(self, df, brand, dimension):\n",
    "        \"\"\"Train and evaluate the model\"\"\"\n",
    "        # Prepare data\n",
    "        X, y = self.prepare_data(df, brand, dimension)\n",
    "        if X is None:\n",
    "            print(f\"Insufficient data for {brand} - {dimension}\")\n",
    "            return None\n",
    "            \n",
    "        # Split training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Convert text to TF-IDF features\n",
    "        X_train_tfidf = self.vectorizer.fit_transform(X_train)\n",
    "        X_test_tfidf = self.vectorizer.transform(X_test)\n",
    "        \n",
    "        # Reset indices\n",
    "        y_train = y_train.reset_index(drop=True)\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "        \n",
    "        # Predict test set\n",
    "        y_pred = []\n",
    "        for i in range(X_test_tfidf.shape[0]):\n",
    "            test_vector = X_test_tfidf[i:i+1]\n",
    "            pred_label = self.classify_review(test_vector, X_train_tfidf, y_train)\n",
    "            y_pred.append(pred_label)\n",
    "            \n",
    "        # Evaluate results\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'report': report,\n",
    "            'positive_ratio': sum(y_pred) / len(y_pred),\n",
    "            'negative_ratio': 1 - (sum(y_pred) / len(y_pred))\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv('all_brands_combined_mobile_data_final.csv')\n",
    "    \n",
    "    # Create classifier\n",
    "    classifier = MobileReviewClassifier(k=5)\n",
    "    \n",
    "    # Define brands to analyze\n",
    "    brands = ['Google Pixel', 'Oppo Find X3 Pro', 'Samsung S24 Ultra', \n",
    "              'Xiaomi 14 Ultra', 'iPhone']\n",
    "    \n",
    "    # Analyze each dimension for each brand\n",
    "    results = {}\n",
    "    \n",
    "    for brand in brands:\n",
    "        print(f\"\\nProcessing {brand}...\")\n",
    "        brand_results = {}\n",
    "        \n",
    "        for dimension in classifier.dimension_keywords.keys():\n",
    "            print(f\"Training classifier for {dimension}\")\n",
    "            result = classifier.train_and_evaluate(df, brand, dimension)\n",
    "            \n",
    "            if result:\n",
    "                brand_results[dimension] = result\n",
    "                print(f\"Accuracy: {result['accuracy']:.2f}\")\n",
    "                print(f\"Positive ratio: {result['positive_ratio']:.2%}\")\n",
    "                print(f\"Negative ratio: {result['negative_ratio']:.2%}\")\n",
    "                print(\"\\nClassification Report:\")\n",
    "                print(result['report'])\n",
    "        \n",
    "        results[brand] = brand_results\n",
    "    \n",
    "    # Print overall results\n",
    "    print(\"\\nOverall Sentiment Analysis Results:\")\n",
    "    for brand in brands:\n",
    "        if brand in results:\n",
    "            print(f\"\\n{brand} Analysis:\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            for dimension, metrics in results[brand].items():\n",
    "                print(f\"\\n{dimension.title()}:\")\n",
    "                print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "                print(f\"Positive ratio: {metrics['positive_ratio']:.2%}\")\n",
    "                print(f\"Negative ratio: {metrics['negative_ratio']:.2%}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c7d86-69f1-4b79-971b-09a4edd43855",
   "metadata": {},
   "source": [
    "## Word2Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "060f26a2-c2ac-482b-ab95-324dfb3d1a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec model...\n",
      "Word2Vec model training completed\n",
      "\n",
      "Processing Google Pixel...\n",
      "Training classifier for battery life\n",
      "Accuracy: 0.77\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87        75\n",
      "           1       0.80      0.15      0.26        26\n",
      "\n",
      "    accuracy                           0.77       101\n",
      "   macro avg       0.79      0.57      0.56       101\n",
      "weighted avg       0.78      0.77      0.71       101\n",
      "\n",
      "Training classifier for camera\n",
      "Accuracy: 0.77\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       115\n",
      "           1       0.86      0.15      0.25        41\n",
      "\n",
      "    accuracy                           0.77       156\n",
      "   macro avg       0.81      0.57      0.56       156\n",
      "weighted avg       0.79      0.77      0.70       156\n",
      "\n",
      "Training classifier for design\n",
      "Accuracy: 0.73\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.84        56\n",
      "           1       0.67      0.09      0.16        22\n",
      "\n",
      "    accuracy                           0.73        78\n",
      "   macro avg       0.70      0.54      0.50        78\n",
      "weighted avg       0.71      0.73      0.65        78\n",
      "\n",
      "Training classifier for display\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90        71\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.83        86\n",
      "   macro avg       0.41      0.50      0.45        86\n",
      "weighted avg       0.68      0.83      0.75        86\n",
      "\n",
      "Training classifier for performance\n",
      "Accuracy: 0.70\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82        76\n",
      "           1       1.00      0.08      0.15        37\n",
      "\n",
      "    accuracy                           0.70       113\n",
      "   macro avg       0.85      0.54      0.48       113\n",
      "weighted avg       0.79      0.70      0.60       113\n",
      "\n",
      "Training classifier for software\n",
      "Accuracy: 0.81\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       244\n",
      "           1       1.00      0.03      0.06        60\n",
      "\n",
      "    accuracy                           0.81       304\n",
      "   macro avg       0.90      0.52      0.48       304\n",
      "weighted avg       0.85      0.81      0.73       304\n",
      "\n",
      "Training classifier for speaker\n",
      "Accuracy: 0.74\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        39\n",
      "           1       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.74        53\n",
      "   macro avg       0.37      0.50      0.42        53\n",
      "weighted avg       0.54      0.74      0.62        53\n",
      "\n",
      "\n",
      "Processing Oppo Find X3 Pro...\n",
      "Training classifier for battery life\n",
      "Accuracy: 0.73\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        30\n",
      "           1       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.73        41\n",
      "   macro avg       0.37      0.50      0.42        41\n",
      "weighted avg       0.54      0.73      0.62        41\n",
      "\n",
      "Training classifier for camera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        54\n",
      "           1       1.00      0.17      0.30        23\n",
      "\n",
      "    accuracy                           0.75        77\n",
      "   macro avg       0.87      0.59      0.57        77\n",
      "weighted avg       0.82      0.75      0.68        77\n",
      "\n",
      "Training classifier for design\n",
      "Accuracy: 0.76\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87        26\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.76        34\n",
      "   macro avg       0.38      0.50      0.43        34\n",
      "weighted avg       0.58      0.76      0.66        34\n",
      "\n",
      "Training classifier for display\n",
      "Accuracy: 0.73\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84        24\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.73        33\n",
      "   macro avg       0.36      0.50      0.42        33\n",
      "weighted avg       0.53      0.73      0.61        33\n",
      "\n",
      "Training classifier for performance\n",
      "Accuracy: 0.66\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79        23\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.66        35\n",
      "   macro avg       0.33      0.50      0.40        35\n",
      "weighted avg       0.43      0.66      0.52        35\n",
      "\n",
      "Training classifier for software\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        79\n",
      "           1       1.00      0.06      0.12        16\n",
      "\n",
      "    accuracy                           0.84        95\n",
      "   macro avg       0.92      0.53      0.52        95\n",
      "weighted avg       0.87      0.84      0.78        95\n",
      "\n",
      "Training classifier for speaker\n",
      "Accuracy: 0.71\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83         5\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.71         7\n",
      "   macro avg       0.36      0.50      0.42         7\n",
      "weighted avg       0.51      0.71      0.60         7\n",
      "\n",
      "\n",
      "Processing Samsung S24 Ultra...\n",
      "Training classifier for battery life\n",
      "Accuracy: 0.82\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        46\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.82        56\n",
      "   macro avg       0.41      0.50      0.45        56\n",
      "weighted avg       0.67      0.82      0.74        56\n",
      "\n",
      "Training classifier for camera\n",
      "Accuracy: 0.72\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        21\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.72        29\n",
      "   macro avg       0.36      0.50      0.42        29\n",
      "weighted avg       0.52      0.72      0.61        29\n",
      "\n",
      "Training classifier for design\n",
      "Accuracy: 0.75\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        18\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.75        24\n",
      "   macro avg       0.38      0.50      0.43        24\n",
      "weighted avg       0.56      0.75      0.64        24\n",
      "\n",
      "Training classifier for display\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        59\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.89        66\n",
      "   macro avg       0.45      0.50      0.47        66\n",
      "weighted avg       0.80      0.89      0.84        66\n",
      "\n",
      "Training classifier for performance\n",
      "Accuracy: 0.71\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        15\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.36      0.50      0.42        21\n",
      "weighted avg       0.51      0.71      0.60        21\n",
      "\n",
      "Training classifier for software\n",
      "Accuracy: 0.84\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        64\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.84        76\n",
      "   macro avg       0.42      0.50      0.46        76\n",
      "weighted avg       0.71      0.84      0.77        76\n",
      "\n",
      "Training classifier for speaker\n",
      "Accuracy: 0.50\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         5\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.50        10\n",
      "   macro avg       0.25      0.50      0.33        10\n",
      "weighted avg       0.25      0.50      0.33        10\n",
      "\n",
      "\n",
      "Processing Xiaomi 14 Ultra...\n",
      "Training classifier for battery life\n",
      "Accuracy: 0.76\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83       141\n",
      "           1       0.77      0.49      0.60        81\n",
      "\n",
      "    accuracy                           0.76       222\n",
      "   macro avg       0.76      0.70      0.72       222\n",
      "weighted avg       0.76      0.76      0.75       222\n",
      "\n",
      "Training classifier for camera\n",
      "Accuracy: 0.77\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.84       221\n",
      "           1       0.88      0.46      0.61       138\n",
      "\n",
      "    accuracy                           0.77       359\n",
      "   macro avg       0.81      0.71      0.72       359\n",
      "weighted avg       0.79      0.77      0.75       359\n",
      "\n",
      "Training classifier for design\n",
      "Accuracy: 0.75\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       113\n",
      "           1       0.64      0.52      0.57        56\n",
      "\n",
      "    accuracy                           0.75       169\n",
      "   macro avg       0.71      0.69      0.70       169\n",
      "weighted avg       0.74      0.75      0.74       169\n",
      "\n",
      "Training classifier for display\n",
      "Accuracy: 0.74\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.87      0.80        77\n",
      "           1       0.71      0.52      0.60        48\n",
      "\n",
      "    accuracy                           0.74       125\n",
      "   macro avg       0.73      0.70      0.70       125\n",
      "weighted avg       0.73      0.74      0.73       125\n",
      "\n",
      "Training classifier for performance\n",
      "Accuracy: 0.76\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84       123\n",
      "           1       0.76      0.44      0.55        64\n",
      "\n",
      "    accuracy                           0.76       187\n",
      "   macro avg       0.76      0.68      0.69       187\n",
      "weighted avg       0.76      0.76      0.74       187\n",
      "\n",
      "Training classifier for software\n",
      "Accuracy: 0.83\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89       375\n",
      "           1       0.90      0.40      0.56       139\n",
      "\n",
      "    accuracy                           0.83       514\n",
      "   macro avg       0.86      0.69      0.72       514\n",
      "weighted avg       0.84      0.83      0.80       514\n",
      "\n",
      "Training classifier for speaker\n",
      "Accuracy: 0.62\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77        31\n",
      "           1       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.62        50\n",
      "   macro avg       0.31      0.50      0.38        50\n",
      "weighted avg       0.38      0.62      0.47        50\n",
      "\n",
      "\n",
      "Processing iPhone...\n",
      "Training classifier for battery life\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       199\n",
      "           1       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.82       244\n",
      "   macro avg       0.41      0.50      0.45       244\n",
      "weighted avg       0.67      0.82      0.73       244\n",
      "\n",
      "Training classifier for camera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       153\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.79       193\n",
      "   macro avg       0.40      0.50      0.44       193\n",
      "weighted avg       0.63      0.79      0.70       193\n",
      "\n",
      "Training classifier for design\n",
      "Accuracy: 0.76\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86        57\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.76        75\n",
      "   macro avg       0.38      0.50      0.43        75\n",
      "weighted avg       0.58      0.76      0.66        75\n",
      "\n",
      "Training classifier for display\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       103\n",
      "           1       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.83       124\n",
      "   macro avg       0.42      0.50      0.45       124\n",
      "weighted avg       0.69      0.83      0.75       124\n",
      "\n",
      "Training classifier for performance\n",
      "Accuracy: 0.82\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        53\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.82        65\n",
      "   macro avg       0.41      0.50      0.45        65\n",
      "weighted avg       0.66      0.82      0.73        65\n",
      "\n",
      "Training classifier for software\n",
      "Accuracy: 0.83\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       198\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.83       238\n",
      "   macro avg       0.42      0.50      0.45       238\n",
      "weighted avg       0.69      0.83      0.76       238\n",
      "\n",
      "Training classifier for speaker\n",
      "Accuracy: 0.81\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        17\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.81        21\n",
      "   macro avg       0.40      0.50      0.45        21\n",
      "weighted avg       0.66      0.81      0.72        21\n",
      "\n",
      "\n",
      "Overall Sentiment Analysis Results:\n",
      "\n",
      "Google Pixel Analysis:\n",
      "--------------------------------------------------\n",
      "\n",
      "Battery Life:\n",
      "Accuracy: 0.77\n",
      "Positive ratio: 4.95%\n",
      "Negative ratio: 95.05%\n",
      "\n",
      "Camera:\n",
      "Accuracy: 0.77\n",
      "Positive ratio: 4.49%\n",
      "Negative ratio: 95.51%\n",
      "\n",
      "Design:\n",
      "Accuracy: 0.73\n",
      "Positive ratio: 3.85%\n",
      "Negative ratio: 96.15%\n",
      "\n",
      "Display:\n",
      "Accuracy: 0.83\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Performance:\n",
      "Accuracy: 0.70\n",
      "Positive ratio: 2.65%\n",
      "Negative ratio: 97.35%\n",
      "\n",
      "Software:\n",
      "Accuracy: 0.81\n",
      "Positive ratio: 0.66%\n",
      "Negative ratio: 99.34%\n",
      "\n",
      "Speaker:\n",
      "Accuracy: 0.74\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Oppo Find X3 Pro Analysis:\n",
      "--------------------------------------------------\n",
      "\n",
      "Battery Life:\n",
      "Accuracy: 0.73\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Camera:\n",
      "Accuracy: 0.75\n",
      "Positive ratio: 5.19%\n",
      "Negative ratio: 94.81%\n",
      "\n",
      "Design:\n",
      "Accuracy: 0.76\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Display:\n",
      "Accuracy: 0.73\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Performance:\n",
      "Accuracy: 0.66\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Software:\n",
      "Accuracy: 0.84\n",
      "Positive ratio: 1.05%\n",
      "Negative ratio: 98.95%\n",
      "\n",
      "Speaker:\n",
      "Accuracy: 0.71\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Samsung S24 Ultra Analysis:\n",
      "--------------------------------------------------\n",
      "\n",
      "Battery Life:\n",
      "Accuracy: 0.82\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Camera:\n",
      "Accuracy: 0.72\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Design:\n",
      "Accuracy: 0.75\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Display:\n",
      "Accuracy: 0.89\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Performance:\n",
      "Accuracy: 0.71\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Software:\n",
      "Accuracy: 0.84\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Speaker:\n",
      "Accuracy: 0.50\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Xiaomi 14 Ultra Analysis:\n",
      "--------------------------------------------------\n",
      "\n",
      "Battery Life:\n",
      "Accuracy: 0.76\n",
      "Positive ratio: 23.42%\n",
      "Negative ratio: 76.58%\n",
      "\n",
      "Camera:\n",
      "Accuracy: 0.77\n",
      "Positive ratio: 20.33%\n",
      "Negative ratio: 79.67%\n",
      "\n",
      "Design:\n",
      "Accuracy: 0.75\n",
      "Positive ratio: 26.63%\n",
      "Negative ratio: 73.37%\n",
      "\n",
      "Display:\n",
      "Accuracy: 0.74\n",
      "Positive ratio: 28.00%\n",
      "Negative ratio: 72.00%\n",
      "\n",
      "Performance:\n",
      "Accuracy: 0.76\n",
      "Positive ratio: 19.79%\n",
      "Negative ratio: 80.21%\n",
      "\n",
      "Software:\n",
      "Accuracy: 0.83\n",
      "Positive ratio: 12.06%\n",
      "Negative ratio: 87.94%\n",
      "\n",
      "Speaker:\n",
      "Accuracy: 0.62\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "iPhone Analysis:\n",
      "--------------------------------------------------\n",
      "\n",
      "Battery Life:\n",
      "Accuracy: 0.82\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Camera:\n",
      "Accuracy: 0.79\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Design:\n",
      "Accuracy: 0.76\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Display:\n",
      "Accuracy: 0.83\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Performance:\n",
      "Accuracy: 0.82\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Software:\n",
      "Accuracy: 0.83\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n",
      "\n",
      "Speaker:\n",
      "Accuracy: 0.81\n",
      "Positive ratio: 0.00%\n",
      "Negative ratio: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\python\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "class Word2VecSvmClassifier:\n",
    "    def __init__(self, vector_size=100):\n",
    "        \"\"\"\n",
    "        Initialize the classifier\n",
    "        vector_size: Dimension of Word2Vec vectors, higher dimensions can capture richer semantic information but require more computational resources\n",
    "        \"\"\"\n",
    "        # Download required NLTK data\n",
    "        nltk.download('punkt', quiet=True)\n",
    "        \n",
    "        self.dimension_keywords = {\n",
    "            'battery life': ['battery', 'battery life', 'charge', 'charging', 'power'],\n",
    "            'camera': ['camera', 'photo', 'picture', 'image', 'photography', 'shoot'],\n",
    "            'design': ['design', 'build', 'look', 'build quality', 'material'],\n",
    "            'display': ['display', 'screen', 'resolution', 'brightness', 'color'],\n",
    "            'performance': ['performance', 'speed', 'fast', 'slow', 'processor', 'lag'],\n",
    "            'software': ['software', 'system', 'os', 'android', 'ios', 'interface'],\n",
    "            'speaker': ['speaker', 'sound', 'audio', 'volume', 'music']\n",
    "        }\n",
    "        \n",
    "        self.target_brands = [\n",
    "            'Google Pixel',\n",
    "            'Oppo Find X3 Pro',\n",
    "            'Samsung S24 Ultra',\n",
    "            'Xiaomi 14 Ultra',\n",
    "            'iPhone'\n",
    "        ]\n",
    "        \n",
    "        self.dimensions = list(self.dimension_keywords.keys())\n",
    "        self.vector_size = vector_size\n",
    "        self.word2vec_model = None\n",
    "        \n",
    "        # Create an SVM classifier for each dimension of each brand\n",
    "        self.classifiers = {\n",
    "            brand: {dim: SVC(kernel='rbf', probability=True) \n",
    "                   for dim in self.dimensions}\n",
    "            for brand in self.target_brands\n",
    "        }\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Clean and tokenize text\n",
    "        Convert text to lowercase, remove special characters, and tokenize\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return []\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove special characters\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "        # Tokenize\n",
    "        return word_tokenize(text)\n",
    "\n",
    "    def train_word2vec(self, texts):\n",
    "        \"\"\"\n",
    "        Train Word2Vec model\n",
    "        Use all review texts to learn word vectors to capture domain-specific word semantics\n",
    "        \"\"\"\n",
    "        print(\"Training Word2Vec model...\")\n",
    "        # Preprocess all texts\n",
    "        processed_texts = [self.preprocess_text(text) for text in texts]\n",
    "        \n",
    "        # Train Word2Vec model\n",
    "        self.word2vec_model = Word2Vec(\n",
    "            sentences=processed_texts,\n",
    "            vector_size=self.vector_size,  # Word vector dimension\n",
    "            window=5,  # Context window size\n",
    "            min_count=1,  # Minimum word frequency\n",
    "            workers=4  # Number of training threads\n",
    "        )\n",
    "        print(\"Word2Vec model training completed\")\n",
    "\n",
    "    def get_text_vector(self, text):\n",
    "        \"\"\"\n",
    "        Convert text to vector representation\n",
    "        Represent entire text by averaging word vectors\n",
    "        \"\"\"\n",
    "        tokens = self.preprocess_text(text)\n",
    "        vectors = []\n",
    "        \n",
    "        for token in tokens:\n",
    "            try:\n",
    "                # Get word vector\n",
    "                vector = self.word2vec_model.wv[token]\n",
    "                vectors.append(vector)\n",
    "            except KeyError:\n",
    "                continue\n",
    "        \n",
    "        if not vectors:\n",
    "            return np.zeros(self.vector_size)\n",
    "        \n",
    "        # Return average of all word vectors\n",
    "        return np.mean(vectors, axis=0)\n",
    "\n",
    "    def prepare_dimension_data(self, texts, brand, dimension):\n",
    "        \"\"\"\n",
    "        Prepare training data for specific brand and dimension\n",
    "        \"\"\"\n",
    "        X = []  # Store text vectors\n",
    "        y = []  # Store sentiment labels\n",
    "        \n",
    "        for text in texts:\n",
    "            # Check if text contains relevant dimension keywords\n",
    "            if any(keyword in text.lower() for keyword in self.dimension_keywords[dimension]):\n",
    "                # Get vector representation of text\n",
    "                text_vector = self.get_text_vector(text)\n",
    "                X.append(text_vector)\n",
    "                \n",
    "                # Determine sentiment label (simplified version, should use annotated data in practice)\n",
    "                sentiment = 1 if any(pos in text.lower() \n",
    "                    for pos in ['good', 'great', 'excellent', 'amazing']) else 0\n",
    "                y.append(sentiment)\n",
    "        \n",
    "        if not X:\n",
    "            return None, None\n",
    "            \n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def train_and_evaluate(self, df):\n",
    "        \"\"\"\n",
    "        Train models and evaluate performance\n",
    "        \"\"\"\n",
    "        # First train Word2Vec model\n",
    "        self.train_word2vec(df['Text'])\n",
    "        \n",
    "        # Filter target brand data\n",
    "        df = df[df['Product Brand'].isin(self.target_brands)]\n",
    "        \n",
    "        # Split training and test sets\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for brand in self.target_brands:\n",
    "            print(f\"\\nProcessing {brand}...\")\n",
    "            brand_results = {}\n",
    "            \n",
    "            brand_train = train_df[train_df['Product Brand'] == brand]\n",
    "            brand_test = test_df[test_df['Product Brand'] == brand]\n",
    "            \n",
    "            for dimension in self.dimensions:\n",
    "                print(f\"Training classifier for {dimension}\")\n",
    "                \n",
    "                # Prepare training data\n",
    "                X_train, y_train = self.prepare_dimension_data(\n",
    "                    brand_train['Text'], brand, dimension\n",
    "                )\n",
    "                \n",
    "                if X_train is None or len(X_train) < 10:\n",
    "                    print(f\"Insufficient data for {brand} - {dimension}\")\n",
    "                    continue\n",
    "                \n",
    "                # Prepare test data\n",
    "                X_test, y_test = self.prepare_dimension_data(\n",
    "                    brand_test['Text'], brand, dimension\n",
    "                )\n",
    "                \n",
    "                if X_test is None or len(X_test) < 5:\n",
    "                    print(f\"Insufficient test data for {brand} - {dimension}\")\n",
    "                    continue\n",
    "                \n",
    "                # Train SVM classifier\n",
    "                classifier = self.classifiers[brand][dimension]\n",
    "                classifier.fit(X_train, y_train)\n",
    "                \n",
    "                # Predict and evaluate\n",
    "                y_pred = classifier.predict(X_test)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                report = classification_report(y_test, y_pred)\n",
    "                \n",
    "                # Save results\n",
    "                brand_results[dimension] = {\n",
    "                    'accuracy': accuracy,\n",
    "                    'report': report,\n",
    "                    'positive_ratio': sum(y_pred == 1) / len(y_pred),\n",
    "                    'negative_ratio': sum(y_pred == 0) / len(y_pred)\n",
    "                }\n",
    "                \n",
    "                print(f\"Accuracy: {accuracy:.2f}\")\n",
    "                print(\"\\nClassification Report:\")\n",
    "                print(report)\n",
    "            \n",
    "            results[brand] = brand_results\n",
    "        \n",
    "        return results\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    df = pd.read_csv('all_brands_combined_mobile_data_final.csv')\n",
    "    \n",
    "    # Create classifier and train/evaluate\n",
    "    classifier = Word2VecSvmClassifier(vector_size=100)\n",
    "    results = classifier.train_and_evaluate(df)\n",
    "    \n",
    "    # Print overall results\n",
    "    print(\"\\nOverall Sentiment Analysis Results:\")\n",
    "    for brand in classifier.target_brands:\n",
    "        if brand in results:\n",
    "            print(f\"\\n{brand} Analysis:\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            for dimension, metrics in results[brand].items():\n",
    "                print(f\"\\n{dimension.title()}:\")\n",
    "                print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "                print(f\"Positive ratio: {metrics['positive_ratio']:.2%}\")\n",
    "                print(f\"Negative ratio: {metrics['negative_ratio']:.2%}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d021ff2c-e109-40fe-99ef-62c673512a68",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b61a60-e336-487f-b5c0-5d8813804f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
